{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant modules from libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data \n",
    "df = pd.read_csv(\"dataset_breastCancer.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the summary of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()  #see data fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()  #see data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()  #see if there is any null field in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the columns which are not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"id\",\"Unnamed: 32\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the dataset that there is one column, diagnosis which is non-numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    30\n",
       "object      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()  #check number of data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"diagnosis\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the target column is categorical, we will proceed with label encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"diagnosis\"]   #target column\n",
    "X = df.drop([\"diagnosis\"], axis=1)   #feature columns\n",
    "y = LabelEncoder().fit_transform(y)  #label encode categorical column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)  #split the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 30)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)   #Scale the features\n",
    "X_test = sc.transform(X_test)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the model and create ANN. Adjust the parameter by observing mse and val_mse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 318 samples, validate on 80 samples\n",
      "Epoch 1/80\n",
      "318/318 [==============================] - 1s 2ms/step - loss: 0.2064 - mse: 0.2064 - val_loss: 0.1499 - val_mse: 0.1499\n",
      "Epoch 2/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0981 - mse: 0.0981 - val_loss: 0.0920 - val_mse: 0.0920\n",
      "Epoch 3/80\n",
      "318/318 [==============================] - 1s 2ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0683 - val_mse: 0.0683\n",
      "Epoch 4/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0483 - mse: 0.0483 - val_loss: 0.0571 - val_mse: 0.0571\n",
      "Epoch 5/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0510 - val_mse: 0.0510\n",
      "Epoch 6/80\n",
      "318/318 [==============================] - 0s 979us/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0475 - val_mse: 0.0475\n",
      "Epoch 7/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0456 - val_mse: 0.0456\n",
      "Epoch 8/80\n",
      "318/318 [==============================] - 0s 891us/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0438 - val_mse: 0.0438\n",
      "Epoch 9/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0429 - val_mse: 0.0429\n",
      "Epoch 10/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 11/80\n",
      "318/318 [==============================] - 0s 960us/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0406 - val_mse: 0.0406\n",
      "Epoch 12/80\n",
      "318/318 [==============================] - 0s 913us/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0403 - val_mse: 0.0403\n",
      "Epoch 13/80\n",
      "318/318 [==============================] - 0s 913us/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0396 - val_mse: 0.0396195    \n",
      "Epoch 14/80\n",
      "318/318 [==============================] - 0s 897us/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 15/80\n",
      "318/318 [==============================] - 0s 841us/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 16/80\n",
      "318/318 [==============================] - 0s 881us/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 17/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 18/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 19/80\n",
      "318/318 [==============================] - 1s 2ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 20/80\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 21/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0373 - val_mse: 0.0373\n",
      "Epoch 22/80\n",
      "318/318 [==============================] - 1s 2ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 23/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0373 - val_mse: 0.0373\n",
      "Epoch 24/80\n",
      "318/318 [==============================] - 0s 938us/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 25/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0369 - val_mse: 0.0369\n",
      "Epoch 26/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0370 - val_mse: 0.0370\n",
      "Epoch 27/80\n",
      "318/318 [==============================] - 0s 910us/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 28/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0371 - val_mse: 0.0371\n",
      "Epoch 29/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 30/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0378 - val_mse: 0.0378\n",
      "Epoch 31/80\n",
      "318/318 [==============================] - 0s 903us/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 32/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 33/80\n",
      "318/318 [==============================] - 0s 960us/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0378 - val_mse: 0.0378\n",
      "Epoch 34/80\n",
      "318/318 [==============================] - 0s 991us/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 35/80\n",
      "318/318 [==============================] - 1s 2ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 36/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 37/80\n",
      "318/318 [==============================] - 0s 878us/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 38/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 39/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 40/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 41/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 42/80\n",
      "318/318 [==============================] - ETA: 0s - loss: 0.0043 - mse: 0.0043     - 0s 894us/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 43/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 44/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 45/80\n",
      "318/318 [==============================] - 0s 928us/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 46/80\n",
      "318/318 [==============================] - 0s 803us/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 47/80\n",
      "318/318 [==============================] - 0s 975us/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 48/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 49/80\n",
      "318/318 [==============================] - 0s 815us/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0396 - val_mse: 0.0396\n",
      "Epoch 50/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 51/80\n",
      "318/318 [==============================] - 1s 2ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0401 - val_mse: 0.0401\n",
      "Epoch 52/80\n",
      "318/318 [==============================] - 0s 903us/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0403 - val_mse: 0.0403\n",
      "Epoch 53/80\n",
      "318/318 [==============================] - 0s 906us/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 54/80\n",
      "318/318 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0406 - val_mse: 0.0406\n",
      "Epoch 55/80\n",
      "318/318 [==============================] - 0s 847us/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 56/80\n",
      "318/318 [==============================] - 0s 834us/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0415 - val_mse: 0.0415\n",
      "Epoch 57/80\n",
      "318/318 [==============================] - 0s 910us/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0420 - val_mse: 0.0420\n",
      "Epoch 58/80\n",
      "318/318 [==============================] - 0s 922us/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 59/80\n",
      "318/318 [==============================] - 0s 837us/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0429 - val_mse: 0.0429\n",
      "Epoch 60/80\n",
      "318/318 [==============================] - 0s 841us/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 61/80\n",
      "318/318 [==============================] - 0s 900us/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0438 - val_mse: 0.0438\n",
      "Epoch 62/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 63/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 64/80\n",
      "318/318 [==============================] - 0s 834us/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 65/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 66/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0454 - val_mse: 0.0454\n",
      "Epoch 67/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0456 - val_mse: 0.0456\n",
      "Epoch 68/80\n",
      "318/318 [==============================] - 1s 2ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0454 - val_mse: 0.0454\n",
      "Epoch 69/80\n",
      "318/318 [==============================] - 0s 903us/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0455 - val_mse: 0.0455\n",
      "Epoch 70/80\n",
      "318/318 [==============================] - 0s 866us/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0456 - val_mse: 0.0456\n",
      "Epoch 71/80\n",
      "318/318 [==============================] - 0s 862us/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0460 - val_mse: 0.0460\n",
      "Epoch 72/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0469 - val_mse: 0.0469\n",
      "Epoch 73/80\n",
      "318/318 [==============================] - 0s 862us/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0465 - val_mse: 0.0465\n",
      "Epoch 74/80\n",
      "318/318 [==============================] - 0s 947us/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 75/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 9.6269e-04 - mse: 9.6269e-04 - val_loss: 0.0466 - val_mse: 0.0466\n",
      "Epoch 76/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 9.1263e-04 - mse: 9.1263e-04 - val_loss: 0.0470 - val_mse: 0.0470\n",
      "Epoch 77/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 8.5094e-04 - mse: 8.5094e-04 - val_loss: 0.0475 - val_mse: 0.0475\n",
      "Epoch 78/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 8.0440e-04 - mse: 8.0440e-04 - val_loss: 0.0477 - val_mse: 0.0477\n",
      "Epoch 79/80\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 8.1450e-04 - mse: 8.1450e-04 - val_loss: 0.0475 - val_mse: 0.0475\n",
      "Epoch 80/80\n",
      "318/318 [==============================] - 0s 866us/step - loss: 7.5642e-04 - mse: 7.5642e-04 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "171/171 [==============================] - 0s 70us/step\n",
      "The test error is 0.015834201127290726\n"
     ]
    }
   ],
   "source": [
    "nn = Sequential()\n",
    "#Adding the layers, first input layer shape is 30\n",
    "nn.add(Dense(15, activation=\"relu\", input_shape=(30,)))\n",
    "nn.add(Dense(1, activation=\"sigmoid\"))\n",
    "#Compile the ANN\n",
    "nn.compile(optimizer=\"adam\",loss=\"mean_squared_error\", metrics=[\"mse\"]) #e = 80\n",
    "#Fit the ANN\n",
    "nn.fit(X_train, y_train, validation_split=0.2, epochs=80, batch_size=5, shuffle = True)  #Tune the parameter to get low mse\n",
    "test_loss, test_error = nn.evaluate(X_test, y_test)\n",
    "print(\"The test error is {}\".format(test_error)) #observe the val_mse to adjust the parameter         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the ANN model and get the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 398 samples, validate on 171 samples\n",
      "Epoch 1/80\n",
      "398/398 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.9070 - val_loss: 0.2236 - val_accuracy: 0.9474\n",
      "Epoch 2/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.9472 - val_loss: 0.1523 - val_accuracy: 0.9649\n",
      "Epoch 3/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.1461 - accuracy: 0.9598 - val_loss: 0.1248 - val_accuracy: 0.9708\n",
      "Epoch 4/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.1223 - accuracy: 0.9598 - val_loss: 0.1085 - val_accuracy: 0.9708\n",
      "Epoch 5/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.1071 - accuracy: 0.9648 - val_loss: 0.0989 - val_accuracy: 0.9708\n",
      "Epoch 6/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9648 - val_loss: 0.0926 - val_accuracy: 0.9708\n",
      "Epoch 7/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0881 - accuracy: 0.9698 - val_loss: 0.0872 - val_accuracy: 0.9766\n",
      "Epoch 8/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0819 - accuracy: 0.9724 - val_loss: 0.0830 - val_accuracy: 0.9825\n",
      "Epoch 9/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9724 - val_loss: 0.0796 - val_accuracy: 0.9825\n",
      "Epoch 10/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0721 - accuracy: 0.9774 - val_loss: 0.0771 - val_accuracy: 0.9825\n",
      "Epoch 11/80\n",
      "398/398 [==============================] - 1s 3ms/step - loss: 0.0686 - accuracy: 0.9749 - val_loss: 0.0749 - val_accuracy: 0.9825\n",
      "Epoch 12/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0652 - accuracy: 0.9774 - val_loss: 0.0735 - val_accuracy: 0.9825\n",
      "Epoch 13/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0622 - accuracy: 0.9774 - val_loss: 0.0721 - val_accuracy: 0.9825\n",
      "Epoch 14/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9824 - val_loss: 0.0714 - val_accuracy: 0.9825\n",
      "Epoch 15/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0567 - accuracy: 0.9824 - val_loss: 0.0703 - val_accuracy: 0.9825\n",
      "Epoch 16/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0546 - accuracy: 0.9849 - val_loss: 0.0712 - val_accuracy: 0.9825\n",
      "Epoch 17/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9899 - val_loss: 0.0699 - val_accuracy: 0.9825\n",
      "Epoch 18/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0498 - accuracy: 0.9874 - val_loss: 0.0712 - val_accuracy: 0.9766\n",
      "Epoch 19/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0482 - accuracy: 0.9849 - val_loss: 0.0722 - val_accuracy: 0.9766\n",
      "Epoch 20/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0461 - accuracy: 0.9899 - val_loss: 0.0726 - val_accuracy: 0.9766\n",
      "Epoch 21/80\n",
      "398/398 [==============================] - 1s 3ms/step - loss: 0.0446 - accuracy: 0.9874 - val_loss: 0.0740 - val_accuracy: 0.9766\n",
      "Epoch 22/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9899 - val_loss: 0.0743 - val_accuracy: 0.9766\n",
      "Epoch 23/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 0.9899 - val_loss: 0.0733 - val_accuracy: 0.9825\n",
      "Epoch 24/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0407 - accuracy: 0.9899 - val_loss: 0.0746 - val_accuracy: 0.9766\n",
      "Epoch 25/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0388 - accuracy: 0.9899 - val_loss: 0.0771 - val_accuracy: 0.9825\n",
      "Epoch 26/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0375 - accuracy: 0.9899 - val_loss: 0.0774 - val_accuracy: 0.9883\n",
      "Epoch 27/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0368 - accuracy: 0.9925 - val_loss: 0.0784 - val_accuracy: 0.9883\n",
      "Epoch 28/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0353 - accuracy: 0.9925 - val_loss: 0.0795 - val_accuracy: 0.9883\n",
      "Epoch 29/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0339 - accuracy: 0.9925 - val_loss: 0.0799 - val_accuracy: 0.9883\n",
      "Epoch 30/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0331 - accuracy: 0.9925 - val_loss: 0.0793 - val_accuracy: 0.9883\n",
      "Epoch 31/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0324 - accuracy: 0.9925 - val_loss: 0.0798 - val_accuracy: 0.9883\n",
      "Epoch 32/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9925 - val_loss: 0.0811 - val_accuracy: 0.9883\n",
      "Epoch 33/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9925 - val_loss: 0.0842 - val_accuracy: 0.9883\n",
      "Epoch 34/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9925 - val_loss: 0.0827 - val_accuracy: 0.9883\n",
      "Epoch 35/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0291 - accuracy: 0.9925 - val_loss: 0.0841 - val_accuracy: 0.9883\n",
      "Epoch 36/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0276 - accuracy: 0.9925 - val_loss: 0.0870 - val_accuracy: 0.9883\n",
      "Epoch 37/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.9925 - val_loss: 0.0870 - val_accuracy: 0.9883\n",
      "Epoch 38/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0270 - accuracy: 0.9925 - val_loss: 0.0891 - val_accuracy: 0.9883\n",
      "Epoch 39/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0257 - accuracy: 0.9925 - val_loss: 0.0902 - val_accuracy: 0.9883\n",
      "Epoch 40/80\n",
      "398/398 [==============================] - 1s 3ms/step - loss: 0.0246 - accuracy: 0.9925 - val_loss: 0.0902 - val_accuracy: 0.9883\n",
      "Epoch 41/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.0913 - val_accuracy: 0.9883\n",
      "Epoch 42/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0241 - accuracy: 0.9925 - val_loss: 0.0935 - val_accuracy: 0.9883\n",
      "Epoch 43/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.0927 - val_accuracy: 0.9883\n",
      "Epoch 44/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9950 - val_loss: 0.0960 - val_accuracy: 0.9883\n",
      "Epoch 45/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9950 - val_loss: 0.0954 - val_accuracy: 0.9883\n",
      "Epoch 46/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0209 - accuracy: 0.9950 - val_loss: 0.0967 - val_accuracy: 0.9883\n",
      "Epoch 47/80\n",
      "398/398 [==============================] - 1s 3ms/step - loss: 0.0203 - accuracy: 0.9950 - val_loss: 0.0990 - val_accuracy: 0.9883\n",
      "Epoch 48/80\n",
      "398/398 [==============================] - 1s 3ms/step - loss: 0.0202 - accuracy: 0.9950 - val_loss: 0.0994 - val_accuracy: 0.9883\n",
      "Epoch 49/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.1014 - val_accuracy: 0.9883\n",
      "Epoch 50/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0186 - accuracy: 0.9950 - val_loss: 0.1017 - val_accuracy: 0.9883\n",
      "Epoch 51/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.1023 - val_accuracy: 0.9883\n",
      "Epoch 52/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 0.9950 - val_loss: 0.1025 - val_accuracy: 0.9883\n",
      "Epoch 53/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 0.1035 - val_accuracy: 0.9883\n",
      "Epoch 54/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 0.9925 - val_loss: 0.1058 - val_accuracy: 0.9883\n",
      "Epoch 55/80\n",
      "398/398 [==============================] - 1s 3ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.1063 - val_accuracy: 0.9883\n",
      "Epoch 56/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 0.1102 - val_accuracy: 0.9883\n",
      "Epoch 57/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 0.1107 - val_accuracy: 0.9883\n",
      "Epoch 58/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.1117 - val_accuracy: 0.9883\n",
      "Epoch 59/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 0.1107 - val_accuracy: 0.9883\n",
      "Epoch 60/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0142 - accuracy: 0.9950 - val_loss: 0.1134 - val_accuracy: 0.9883\n",
      "Epoch 61/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0139 - accuracy: 0.9950 - val_loss: 0.1121 - val_accuracy: 0.9883\n",
      "Epoch 62/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0132 - accuracy: 0.9950 - val_loss: 0.1152 - val_accuracy: 0.9883\n",
      "Epoch 63/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 0.9975 - val_loss: 0.1181 - val_accuracy: 0.9883\n",
      "Epoch 64/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0127 - accuracy: 0.9975 - val_loss: 0.1171 - val_accuracy: 0.9883\n",
      "Epoch 65/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0126 - accuracy: 0.9975 - val_loss: 0.1203 - val_accuracy: 0.9883\n",
      "Epoch 66/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9883\n",
      "Epoch 67/80\n",
      "398/398 [==============================] - 1s 3ms/step - loss: 0.0122 - accuracy: 0.9975 - val_loss: 0.1227 - val_accuracy: 0.9883\n",
      "Epoch 68/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9883\n",
      "Epoch 69/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.1189 - val_accuracy: 0.9883\n",
      "Epoch 70/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.1196 - val_accuracy: 0.9883\n",
      "Epoch 71/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.1230 - val_accuracy: 0.9883\n",
      "Epoch 72/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0103 - accuracy: 0.9975 - val_loss: 0.1284 - val_accuracy: 0.9883\n",
      "Epoch 73/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9883\n",
      "Epoch 74/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 0.9975 - val_loss: 0.1287 - val_accuracy: 0.9883\n",
      "Epoch 75/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9883\n",
      "Epoch 76/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1297 - val_accuracy: 0.9883\n",
      "Epoch 77/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.9883\n",
      "Epoch 78/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.1339 - val_accuracy: 0.9883\n",
      "Epoch 79/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9883\n",
      "Epoch 80/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9883\n",
      "The test accuracy is 0.9824561476707458\n"
     ]
    }
   ],
   "source": [
    "nn = Sequential()\n",
    "nn.add(Dense(15, activation=\"relu\", input_shape=(30,)))\n",
    "nn.add(Dense(1, activation=\"sigmoid\"))\n",
    "#Compile the ANN\n",
    "nn.compile(optimizer=\"adam\",loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "#Fit the ANN\n",
    "his = nn.fit(X_train, y_train, epochs=80, batch_size=5, shuffle = True, validation_data = (X_test, y_test))\n",
    "print(\"The test accuracy is {}\".format(test_acc))  #get the test acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_plt = his.history\n",
    "loss_value = loss_plt[\"loss\"]          \n",
    "val_lossval = loss_plt[\"val_loss\"]\n",
    "epochs = range(1, len(loss_value) + 1)\n",
    "plt.plot(epochs, loss_value, \"r\", label=\"Training\")\n",
    "plt.plot(epochs, val_lossval, \"b\", label=\"Validation\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training loss vs Validation loss\", fontweight=\"bold\", fontsize=12)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the model overfits, let try to handle the overfitting either by 1) removing the network capacity (by removing additional layers), 2) use dropout layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using First method: removing additional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 398 samples, validate on 171 samples\n",
      "Epoch 1/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 1.2976 - accuracy: 0.2111 - val_loss: 1.0055 - val_accuracy: 0.2982\n",
      "Epoch 2/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.7824 - accuracy: 0.4849 - val_loss: 0.5927 - val_accuracy: 0.6491\n",
      "Epoch 3/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7764 - val_loss: 0.4019 - val_accuracy: 0.9064\n",
      "Epoch 4/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.3889 - accuracy: 0.8970 - val_loss: 0.3074 - val_accuracy: 0.9649\n",
      "Epoch 5/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.3175 - accuracy: 0.9196 - val_loss: 0.2511 - val_accuracy: 0.9766\n",
      "Epoch 6/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.2711 - accuracy: 0.9296 - val_loss: 0.2163 - val_accuracy: 0.9825\n",
      "Epoch 7/80\n",
      "398/398 [==============================] - 0s 922us/step - loss: 0.2389 - accuracy: 0.9372 - val_loss: 0.1907 - val_accuracy: 0.9942\n",
      "Epoch 8/80\n",
      "398/398 [==============================] - 0s 875us/step - loss: 0.2146 - accuracy: 0.9422 - val_loss: 0.1714 - val_accuracy: 0.9942\n",
      "Epoch 9/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.1956 - accuracy: 0.9447 - val_loss: 0.1569 - val_accuracy: 0.9942\n",
      "Epoch 10/80\n",
      "398/398 [==============================] - 0s 847us/step - loss: 0.1804 - accuracy: 0.9472 - val_loss: 0.1452 - val_accuracy: 0.9942\n",
      "Epoch 11/80\n",
      "398/398 [==============================] - 0s 852us/step - loss: 0.1678 - accuracy: 0.9598 - val_loss: 0.1353 - val_accuracy: 0.9942\n",
      "Epoch 12/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9623 - val_loss: 0.1277 - val_accuracy: 0.9942\n",
      "Epoch 13/80\n",
      "398/398 [==============================] - 0s 849us/step - loss: 0.1485 - accuracy: 0.9623 - val_loss: 0.1210 - val_accuracy: 0.9942\n",
      "Epoch 14/80\n",
      "398/398 [==============================] - 0s 860us/step - loss: 0.1408 - accuracy: 0.9623 - val_loss: 0.1153 - val_accuracy: 0.9942\n",
      "Epoch 15/80\n",
      "398/398 [==============================] - 0s 935us/step - loss: 0.1342 - accuracy: 0.9648 - val_loss: 0.1103 - val_accuracy: 0.9942\n",
      "Epoch 16/80\n",
      "398/398 [==============================] - 0s 917us/step - loss: 0.1285 - accuracy: 0.9673 - val_loss: 0.1060 - val_accuracy: 0.9942\n",
      "Epoch 17/80\n",
      "398/398 [==============================] - 0s 819us/step - loss: 0.1234 - accuracy: 0.9673 - val_loss: 0.1026 - val_accuracy: 0.9942\n",
      "Epoch 18/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.1189 - accuracy: 0.9698 - val_loss: 0.0990 - val_accuracy: 0.9942\n",
      "Epoch 19/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.1149 - accuracy: 0.9724 - val_loss: 0.0960 - val_accuracy: 0.9942\n",
      "Epoch 20/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9724 - val_loss: 0.0933 - val_accuracy: 0.9942\n",
      "Epoch 21/80\n",
      "398/398 [==============================] - 0s 925us/step - loss: 0.1081 - accuracy: 0.9724 - val_loss: 0.0906 - val_accuracy: 0.9942\n",
      "Epoch 22/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9724 - val_loss: 0.0887 - val_accuracy: 0.9942\n",
      "Epoch 23/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.1023 - accuracy: 0.9749 - val_loss: 0.0866 - val_accuracy: 0.9942\n",
      "Epoch 24/80\n",
      "398/398 [==============================] - 0s 942us/step - loss: 0.0999 - accuracy: 0.9749 - val_loss: 0.0848 - val_accuracy: 0.9942\n",
      "Epoch 25/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9749 - val_loss: 0.0833 - val_accuracy: 0.9942\n",
      "Epoch 26/80\n",
      "398/398 [==============================] - 0s 1000us/step - loss: 0.0955 - accuracy: 0.9774 - val_loss: 0.0817 - val_accuracy: 0.9942\n",
      "Epoch 27/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0937 - accuracy: 0.9774 - val_loss: 0.0804 - val_accuracy: 0.9942\n",
      "Epoch 28/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9799 - val_loss: 0.0789 - val_accuracy: 0.9942\n",
      "Epoch 29/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9799 - val_loss: 0.0778 - val_accuracy: 0.9942\n",
      "Epoch 30/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9799 - val_loss: 0.0767 - val_accuracy: 0.9942\n",
      "Epoch 31/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9799 - val_loss: 0.0757 - val_accuracy: 0.9942\n",
      "Epoch 32/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0856 - accuracy: 0.9799 - val_loss: 0.0745 - val_accuracy: 0.9942\n",
      "Epoch 33/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0843 - accuracy: 0.9799 - val_loss: 0.0738 - val_accuracy: 0.9942\n",
      "Epoch 34/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0830 - accuracy: 0.9799 - val_loss: 0.0729 - val_accuracy: 0.9942\n",
      "Epoch 35/80\n",
      "398/398 [==============================] - 0s 900us/step - loss: 0.0819 - accuracy: 0.9799 - val_loss: 0.0720 - val_accuracy: 0.9942\n",
      "Epoch 36/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0807 - accuracy: 0.9799 - val_loss: 0.0712 - val_accuracy: 0.9942\n",
      "Epoch 37/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.9799 - val_loss: 0.0707 - val_accuracy: 0.9942\n",
      "Epoch 38/80\n",
      "398/398 [==============================] - 0s 952us/step - loss: 0.0787 - accuracy: 0.9799 - val_loss: 0.0698 - val_accuracy: 0.9942\n",
      "Epoch 39/80\n",
      "398/398 [==============================] - 0s 962us/step - loss: 0.0777 - accuracy: 0.9799 - val_loss: 0.0694 - val_accuracy: 0.9942\n",
      "Epoch 40/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0768 - accuracy: 0.9824 - val_loss: 0.0687 - val_accuracy: 0.9942\n",
      "Epoch 41/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9824 - val_loss: 0.0683 - val_accuracy: 0.9942\n",
      "Epoch 42/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0753 - accuracy: 0.9824 - val_loss: 0.0676 - val_accuracy: 0.9942\n",
      "Epoch 43/80\n",
      "398/398 [==============================] - 0s 967us/step - loss: 0.0742 - accuracy: 0.9824 - val_loss: 0.0672 - val_accuracy: 0.9942\n",
      "Epoch 44/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0737 - accuracy: 0.9824 - val_loss: 0.0668 - val_accuracy: 0.9942\n",
      "Epoch 45/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0728 - accuracy: 0.9824 - val_loss: 0.0663 - val_accuracy: 0.9942\n",
      "Epoch 46/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0722 - accuracy: 0.9824 - val_loss: 0.0659 - val_accuracy: 0.9942\n",
      "Epoch 47/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0715 - accuracy: 0.9824 - val_loss: 0.0656 - val_accuracy: 0.9942\n",
      "Epoch 48/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9824 - val_loss: 0.0652 - val_accuracy: 0.9942\n",
      "Epoch 49/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0703 - accuracy: 0.9824 - val_loss: 0.0648 - val_accuracy: 0.9942\n",
      "Epoch 50/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 0.9824 - val_loss: 0.0644 - val_accuracy: 0.9942\n",
      "Epoch 51/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0692 - accuracy: 0.9824 - val_loss: 0.0641 - val_accuracy: 0.9942\n",
      "Epoch 52/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0686 - accuracy: 0.9824 - val_loss: 0.0639 - val_accuracy: 0.9942\n",
      "Epoch 53/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0681 - accuracy: 0.9824 - val_loss: 0.0636 - val_accuracy: 0.9942\n",
      "Epoch 54/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0677 - accuracy: 0.9824 - val_loss: 0.0633 - val_accuracy: 0.9942\n",
      "Epoch 55/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0670 - accuracy: 0.9824 - val_loss: 0.0631 - val_accuracy: 0.9942\n",
      "Epoch 56/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9824 - val_loss: 0.0629 - val_accuracy: 0.9942\n",
      "Epoch 57/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0662 - accuracy: 0.9849 - val_loss: 0.0626 - val_accuracy: 0.9942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0657 - accuracy: 0.9849 - val_loss: 0.0624 - val_accuracy: 0.9942\n",
      "Epoch 59/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9849 - val_loss: 0.0621 - val_accuracy: 0.9942\n",
      "Epoch 60/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0649 - accuracy: 0.9849 - val_loss: 0.0619 - val_accuracy: 0.9942\n",
      "Epoch 61/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0645 - accuracy: 0.9849 - val_loss: 0.0618 - val_accuracy: 0.9942\n",
      "Epoch 62/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.9849 - val_loss: 0.0615 - val_accuracy: 0.9942\n",
      "Epoch 63/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0637 - accuracy: 0.9849 - val_loss: 0.0614 - val_accuracy: 0.9942\n",
      "Epoch 64/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 0.9849 - val_loss: 0.0612 - val_accuracy: 0.9942\n",
      "Epoch 65/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0630 - accuracy: 0.9849 - val_loss: 0.0611 - val_accuracy: 0.9942\n",
      "Epoch 66/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0628 - accuracy: 0.9849 - val_loss: 0.0610 - val_accuracy: 0.9942\n",
      "Epoch 67/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0623 - accuracy: 0.9849 - val_loss: 0.0607 - val_accuracy: 0.9942\n",
      "Epoch 68/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0620 - accuracy: 0.9849 - val_loss: 0.0607 - val_accuracy: 0.9942\n",
      "Epoch 69/80\n",
      "398/398 [==============================] - 0s 977us/step - loss: 0.0618 - accuracy: 0.9849 - val_loss: 0.0605 - val_accuracy: 0.9942\n",
      "Epoch 70/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0615 - accuracy: 0.9849 - val_loss: 0.0604 - val_accuracy: 0.9942\n",
      "Epoch 71/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0611 - accuracy: 0.9849 - val_loss: 0.0603 - val_accuracy: 0.9942\n",
      "Epoch 72/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0608 - accuracy: 0.9849 - val_loss: 0.0602 - val_accuracy: 0.9942\n",
      "Epoch 73/80\n",
      "398/398 [==============================] - 1s 3ms/step - loss: 0.0605 - accuracy: 0.9849 - val_loss: 0.0601 - val_accuracy: 0.9942\n",
      "Epoch 74/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0603 - accuracy: 0.9849 - val_loss: 0.0599 - val_accuracy: 0.9942\n",
      "Epoch 75/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9849 - val_loss: 0.0598 - val_accuracy: 0.9942\n",
      "Epoch 76/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0598 - accuracy: 0.9849 - val_loss: 0.0597 - val_accuracy: 0.9942\n",
      "Epoch 77/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0595 - accuracy: 0.9849 - val_loss: 0.0597 - val_accuracy: 0.9942\n",
      "Epoch 78/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0593 - accuracy: 0.9849 - val_loss: 0.0596 - val_accuracy: 0.9942\n",
      "Epoch 79/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0590 - accuracy: 0.9849 - val_loss: 0.0595 - val_accuracy: 0.9942\n",
      "Epoch 80/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0589 - accuracy: 0.9849 - val_loss: 0.0596 - val_accuracy: 0.9942\n",
      "The test accuracy is 0.9824561476707458\n"
     ]
    }
   ],
   "source": [
    "nna = Sequential()\n",
    "#remove first input layer\n",
    "#nn.add(Dense(15, activation=\"relu\", input_shape=(30,)))\n",
    "nna.add(Dense(1, activation=\"sigmoid\"))\n",
    "#Compile the ANN\n",
    "nna.compile(optimizer=\"adam\",loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "#Fit the ANN\n",
    "hisa = nna.fit(X_train, y_train, epochs=80, batch_size=5, shuffle = True, validation_data = (X_test, y_test))\n",
    "print(\"The test accuracy is {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_plt = hisa.history\n",
    "loss_value = loss_plt[\"loss\"]          \n",
    "val_lossval = loss_plt[\"val_loss\"]\n",
    "epochs = range(1, len(loss_value) + 1)\n",
    "plt.plot(epochs, loss_value, \"m\", label=\"Training\")\n",
    "plt.plot(epochs, val_lossval, \"g\", label=\"Validation\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training loss vs Validation loss\", fontweight=\"bold\", fontsize=12)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using second method: add dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 398 samples, validate on 171 samples\n",
      "Epoch 1/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.5897 - accuracy: 0.6784 - val_loss: 0.2602 - val_accuracy: 0.9708\n",
      "Epoch 2/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.2908 - accuracy: 0.9296 - val_loss: 0.1496 - val_accuracy: 0.9825\n",
      "Epoch 3/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.1987 - accuracy: 0.9548 - val_loss: 0.1083 - val_accuracy: 0.9883\n",
      "Epoch 4/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.1589 - accuracy: 0.9523 - val_loss: 0.0884 - val_accuracy: 0.9825\n",
      "Epoch 5/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.1397 - accuracy: 0.9497 - val_loss: 0.0793 - val_accuracy: 0.9883\n",
      "Epoch 6/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.1150 - accuracy: 0.9698 - val_loss: 0.0710 - val_accuracy: 0.9883\n",
      "Epoch 7/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9724 - val_loss: 0.0657 - val_accuracy: 0.9883\n",
      "Epoch 8/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0875 - accuracy: 0.9648 - val_loss: 0.0624 - val_accuracy: 0.9883\n",
      "Epoch 9/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0850 - accuracy: 0.9749 - val_loss: 0.0595 - val_accuracy: 0.9883\n",
      "Epoch 10/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0737 - accuracy: 0.9799 - val_loss: 0.0581 - val_accuracy: 0.9883\n",
      "Epoch 11/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0861 - accuracy: 0.9648 - val_loss: 0.0563 - val_accuracy: 0.9883\n",
      "Epoch 12/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0654 - accuracy: 0.9774 - val_loss: 0.0552 - val_accuracy: 0.9942\n",
      "Epoch 13/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0637 - accuracy: 0.9849 - val_loss: 0.0537 - val_accuracy: 0.9942\n",
      "Epoch 14/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0643 - accuracy: 0.9774 - val_loss: 0.0534 - val_accuracy: 0.9942\n",
      "Epoch 15/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0652 - accuracy: 0.9799 - val_loss: 0.0531 - val_accuracy: 0.9942\n",
      "Epoch 16/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0661 - accuracy: 0.9824 - val_loss: 0.0523 - val_accuracy: 0.9942\n",
      "Epoch 17/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0662 - accuracy: 0.9774 - val_loss: 0.0525 - val_accuracy: 0.9942\n",
      "Epoch 18/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0541 - accuracy: 0.9849 - val_loss: 0.0519 - val_accuracy: 0.9942\n",
      "Epoch 19/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0578 - accuracy: 0.9849 - val_loss: 0.0514 - val_accuracy: 0.9942\n",
      "Epoch 20/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0613 - accuracy: 0.9799 - val_loss: 0.0511 - val_accuracy: 0.9942\n",
      "Epoch 21/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0493 - accuracy: 0.9799 - val_loss: 0.0507 - val_accuracy: 0.9942\n",
      "Epoch 22/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9749 - val_loss: 0.0505 - val_accuracy: 0.9942\n",
      "Epoch 23/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0506 - accuracy: 0.9799 - val_loss: 0.0502 - val_accuracy: 0.9942\n",
      "Epoch 24/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0526 - accuracy: 0.9849 - val_loss: 0.0497 - val_accuracy: 0.9942\n",
      "Epoch 25/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0452 - accuracy: 0.9799 - val_loss: 0.0496 - val_accuracy: 0.9942\n",
      "Epoch 26/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0545 - accuracy: 0.9824 - val_loss: 0.0499 - val_accuracy: 0.9942\n",
      "Epoch 27/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9874 - val_loss: 0.0499 - val_accuracy: 0.9942\n",
      "Epoch 28/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0530 - accuracy: 0.9899 - val_loss: 0.0497 - val_accuracy: 0.9942\n",
      "Epoch 29/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9824 - val_loss: 0.0500 - val_accuracy: 0.9942\n",
      "Epoch 30/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0432 - accuracy: 0.9899 - val_loss: 0.0503 - val_accuracy: 0.9942\n",
      "Epoch 31/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0437 - accuracy: 0.9899 - val_loss: 0.0501 - val_accuracy: 0.9942\n",
      "Epoch 32/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0510 - val_accuracy: 0.9942\n",
      "Epoch 33/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0398 - accuracy: 0.9925 - val_loss: 0.0516 - val_accuracy: 0.9942\n",
      "Epoch 34/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0397 - accuracy: 0.9824 - val_loss: 0.0515 - val_accuracy: 0.9942\n",
      "Epoch 35/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 0.9950 - val_loss: 0.0517 - val_accuracy: 0.9942\n",
      "Epoch 36/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0351 - accuracy: 0.9874 - val_loss: 0.0510 - val_accuracy: 0.9942\n",
      "Epoch 37/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0396 - accuracy: 0.9824 - val_loss: 0.0516 - val_accuracy: 0.9942\n",
      "Epoch 38/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0330 - accuracy: 0.9874 - val_loss: 0.0515 - val_accuracy: 0.9942\n",
      "Epoch 39/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.0529 - val_accuracy: 0.9942\n",
      "Epoch 40/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0330 - accuracy: 0.9899 - val_loss: 0.0532 - val_accuracy: 0.9942\n",
      "Epoch 41/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0318 - accuracy: 0.9899 - val_loss: 0.0524 - val_accuracy: 0.9942\n",
      "Epoch 42/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0332 - accuracy: 0.9899 - val_loss: 0.0510 - val_accuracy: 0.9942\n",
      "Epoch 43/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0313 - accuracy: 0.9874 - val_loss: 0.0519 - val_accuracy: 0.9942\n",
      "Epoch 44/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0320 - accuracy: 0.9899 - val_loss: 0.0516 - val_accuracy: 0.9942\n",
      "Epoch 45/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 0.9899 - val_loss: 0.0515 - val_accuracy: 0.9942\n",
      "Epoch 46/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0390 - accuracy: 0.9849 - val_loss: 0.0514 - val_accuracy: 0.9942\n",
      "Epoch 47/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0361 - accuracy: 0.9899 - val_loss: 0.0538 - val_accuracy: 0.9942\n",
      "Epoch 48/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0370 - accuracy: 0.9799 - val_loss: 0.0548 - val_accuracy: 0.9942\n",
      "Epoch 49/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0297 - accuracy: 0.9925 - val_loss: 0.0556 - val_accuracy: 0.9942\n",
      "Epoch 50/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0272 - accuracy: 0.9925 - val_loss: 0.0545 - val_accuracy: 0.9942\n",
      "Epoch 51/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9824 - val_loss: 0.0543 - val_accuracy: 0.9942\n",
      "Epoch 52/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0307 - accuracy: 0.9899 - val_loss: 0.0550 - val_accuracy: 0.9942\n",
      "Epoch 53/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0278 - accuracy: 0.9874 - val_loss: 0.0541 - val_accuracy: 0.9942\n",
      "Epoch 54/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0283 - accuracy: 0.9925 - val_loss: 0.0569 - val_accuracy: 0.9883\n",
      "Epoch 55/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9925 - val_loss: 0.0572 - val_accuracy: 0.9883\n",
      "Epoch 56/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0276 - accuracy: 0.9899 - val_loss: 0.0567 - val_accuracy: 0.9942\n",
      "Epoch 57/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0277 - accuracy: 0.9899 - val_loss: 0.0570 - val_accuracy: 0.9942\n",
      "Epoch 58/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0255 - accuracy: 0.9899 - val_loss: 0.0569 - val_accuracy: 0.9883\n",
      "Epoch 59/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0286 - accuracy: 0.9899 - val_loss: 0.0564 - val_accuracy: 0.9942\n",
      "Epoch 60/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0266 - accuracy: 0.9925 - val_loss: 0.0559 - val_accuracy: 0.9942\n",
      "Epoch 61/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 0.9925 - val_loss: 0.0559 - val_accuracy: 0.9942\n",
      "Epoch 62/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9899 - val_loss: 0.0551 - val_accuracy: 0.9942\n",
      "Epoch 63/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0331 - accuracy: 0.9849 - val_loss: 0.0551 - val_accuracy: 0.9942\n",
      "Epoch 64/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0236 - accuracy: 0.9925 - val_loss: 0.0558 - val_accuracy: 0.9942\n",
      "Epoch 65/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9925 - val_loss: 0.0559 - val_accuracy: 0.9942\n",
      "Epoch 66/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0259 - accuracy: 0.9899 - val_loss: 0.0564 - val_accuracy: 0.9942\n",
      "Epoch 67/80\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.0303 - accuracy: 0.9925 - val_loss: 0.0541 - val_accuracy: 0.9942\n",
      "Epoch 68/80\n",
      "398/398 [==============================] - 1s 3ms/step - loss: 0.0295 - accuracy: 0.9874 - val_loss: 0.0577 - val_accuracy: 0.9942\n",
      "Epoch 69/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0186 - accuracy: 0.9975 - val_loss: 0.0584 - val_accuracy: 0.9942\n",
      "Epoch 70/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.0566 - val_accuracy: 0.9942\n",
      "Epoch 71/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0301 - accuracy: 0.9874 - val_loss: 0.0597 - val_accuracy: 0.9883\n",
      "Epoch 72/80\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9925 - val_loss: 0.0596 - val_accuracy: 0.9883\n",
      "Epoch 73/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9925 - val_loss: 0.0614 - val_accuracy: 0.9883\n",
      "Epoch 74/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0331 - accuracy: 0.9925 - val_loss: 0.0696 - val_accuracy: 0.9883\n",
      "Epoch 75/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9950 - val_loss: 0.0629 - val_accuracy: 0.9883\n",
      "Epoch 76/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0195 - accuracy: 0.9950 - val_loss: 0.0648 - val_accuracy: 0.9883\n",
      "Epoch 77/80\n",
      "398/398 [==============================] - 1s 3ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.0643 - val_accuracy: 0.9883\n",
      "Epoch 78/80\n",
      "398/398 [==============================] - 1s 3ms/step - loss: 0.0221 - accuracy: 0.9950 - val_loss: 0.0643 - val_accuracy: 0.9883\n",
      "Epoch 79/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0144 - accuracy: 0.9950 - val_loss: 0.0670 - val_accuracy: 0.9883\n",
      "Epoch 80/80\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.0170 - accuracy: 0.9950 - val_loss: 0.0636 - val_accuracy: 0.9883\n",
      "The test accuracy is 0.9824561476707458\n"
     ]
    }
   ],
   "source": [
    "#removing additional layer\n",
    "nnb = Sequential()\n",
    "nnb.add(Dense(15, activation=\"relu\", input_shape=(30,)))\n",
    "#add droput layer\n",
    "nnb.add(Dropout(rate=0.2))\n",
    "nnb.add(Dense(1, activation=\"sigmoid\"))\n",
    "#Compile the ANN\n",
    "nnb.compile(optimizer=\"adam\",loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "#Fit the ANN\n",
    "hisb = nnb.fit(X_train, y_train, epochs=80, batch_size=5, shuffle = True, validation_data = (X_test, y_test))\n",
    "print(\"The test accuracy is {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lossplt = hisb.history\n",
    "lossvalue = lossplt[\"loss\"]          \n",
    "vallossval = lossplt[\"val_loss\"]\n",
    "epochs = range(1, len(lossvalue) + 1)\n",
    "plt.plot(epochs, lossvalue, \"c\", label=\"Training\")\n",
    "plt.plot(epochs, vallossval, \"y\", label=\"Validation\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training loss vs Validation loss\", fontweight=\"bold\", fontsize=12)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of the validation accuracy of the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First model - val_accuracy: 0.988304078578949\n",
      "Second model(remove layer) - val_accuracy: 0.9941520690917969\n",
      "Third model(add dropout) - val_accuracy: 0.988304078578949\n"
     ]
    }
   ],
   "source": [
    "print(\"First model - val_accuracy: {}\".format(his.history[\"val_accuracy\"][-1]))\n",
    "print(\"Second model(remove layer) - val_accuracy: {}\".format(hisa.history[\"val_accuracy\"][-1]))\n",
    "print(\"Third model(add dropout) - val_accuracy: {}\".format(hisb.history[\"val_accuracy\"][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the second model has the highest validation accuracy, however, the test accuracy for the three models are\n",
    "the same. Based on the loss graph, the second model fits better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_523\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_307 (Dense)            (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nna.summary()  #second model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
